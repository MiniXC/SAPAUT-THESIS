@misc{nemo_documentation,
title={Punctuation — nemo 0.10.1 documentation},
url={https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en\\/v0.10.1/nlp/punctuation.html},
journal={docs.nvidia.com},
author={E. Bakhturina},
year={2019}
}

@INPROCEEDINGS{transfer_learning_sota,

  author={K. Makhija and T. Ho and E. Chng},

  booktitle={2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 

  title={Transfer Learning for Punctuation Prediction}, 

  year={2019},

  volume={},

  number={},

  pages={268-273},

  doi={10.1109/APSIPAASC47483.2019.9023200}}

@inproceedings{wsj,
author = {P. B. Douglas and J. M. Baker},
title = {The Design for the Wall Street Journal-Based CSR Corpus},
year = {1992},
isbn = {1558602720},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1075527.1075614},
doi = {10.3115/1075527.1075614},
abstract = {The DARPA Spoken Language System (SLS) community has long taken a leadership position in designing, implementing, and globally distributing significant speech corpora widely used for advancing speech recognition research. The Wall Street Journal (WSJ) CSR Corpus described here is the newest addition to this valuable set of resources. In contrast to previous corpora, the WSJ corpus will provide DARPA its first general-purpose English, large vocabulary, natural language, high perplexity, corpus containing significant quantities of both speech data (400 hrs.) and text data (47M words), thereby providing a means to integrate speech recognition and natural language processing in application domains with high potential practical value. This paper presents the motivating goals, acoustic data design, text processing steps, lexicons, and testing paradigms incorporated into the multi-faceted WSJ CSR Corpus.},
booktitle = {Proceedings of the Workshop on Speech and Natural Language},
pages = {357–362},
numpages = {6},
location = {Harriman, New York},
series = {HLT '91}
}

@techreport{browncorpus,
  added-at = {2008-02-29T17:14:20.000+0100},
  author = {W. N. Francis and H. Kucera},
  biburl = {https://www.bibsonomy.org/bibtex/260bb0c74c2ecced0632393e47eb64f48/sb3000},
  institution = {Department of Linguistics, Brown University, Providence, Rhode Island, US},
  interhash = {119c367841941ad1a8f0db35d9f1c0b9},
  intrahash = {60bb0c74c2ecced0632393e47eb64f48},
  keywords = {corpus linguistics text-mining},
  timestamp = {2008-02-29T17:14:20.000+0100},
  title = {Brown Corpus Manual},
  url = {http://icame.uib.no/brown/bcm.html},
  year = 1979
}

@INPROCEEDINGS{beeferman1998,
  author={D. {Beeferman} and A. {Berger} and J. {Lafferty}},
  booktitle={Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)}, 
  title={Cyberpunc: a lightweight punctuation annotation system for speech}, 
  year={1998},
  volume={2},
  number={},
  pages={689-692 vol.2},
  doi={10.1109/ICASSP.1998.675358}}
  
@article{palmer1995satz,
  title={SATZ-an adaptive sentence segmentation system},
  author={Palmer, David D},
  journal={arXiv preprint cmp-lg/9503019},
  year={1995}
}

@article{christensen2001,
  title={Punctuation annotation using statistical prosody models.},
  author={H. Christensen and Y. Gotoh and S. Renals},
  year={2001}
}

@misc{hub4,
  doi = {10.35111/Q5W8-6V93},
  url = {https://catalog.ldc.upenn.edu/LDC98S71},
  author = {J. G. Fiscus and J. S. Garofolo and {M Przybocki} and {W. Fisher} and {D. Pallett}},
  title = {1997 English Broadcast News Speech (HUB4)},
  publisher = {Linguistic Data Consortium},
  year = {1998}
}

@article{batista2008,
  title={Recovering capitalization and punctuation marks for automatic speech recognition: Case study for Portuguese broadcast news},
  author={F. Batista and D. Caseiro and N. Mamede and I. Trancoso},
  journal={Speech Communication},
  volume={50},
  number={10},
  pages={847--862},
  year={2008},
  publisher={Elsevier}
}

@INPROCEEDINGS{yi2019speech2vec,
  author={J. {Yi} and J. {Tao}},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Self-attention Based Model for Punctuation Prediction Using Word and Speech Embeddings}, 
  year={2019},
  volume={},
  number={},
  pages={7270-7274},
  doi={10.1109/ICASSP.2019.8682260}}
  
@inproceedings{Klejch2016,  title     = "Punctuated Transcription of Multi-genre Broadcasts Using Acoustic and Lexical Approaches",  abstract  = "In this paper we investigate the punctuated transcription of multi-genre broadcast media. We examine four systems, three of which are based on lexical features, the fourth of which uses acoustic features by integrating punctuation into the speech recognition acoustic models. We also explore the combination of these component systems using voting and log-linear interpolation. We performed experiments on the English language MGB Challenge data, which comprises about 1,600h of BBC television recordings. Our results indicate that a lexical system, based on a neural machine translation approach is significantly better than other systems achieving an F-Measure of .626 on reference text, with a relative degradation of .19 on ASR output. Our analysis of the results in terms of specific punctuation indicated that using longer context improves the prediction of question marks and acoustic information improves prediction of exclamation marks. Finally, we show that even though the systems are complementary, their straightforward combination does not yield better F-measure",  author    = "O. Klejch and P. Bell and S. Renals",  year      = "2016",  month     = feb,  day       = "9",  doi       = "10.1109/SLT.2016.7846300",  language  = "English",  pages     = "433--440",  booktitle = "2016 IEEE Workshop on Spoken Language Technology",  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",  address   = "United States",  note      = "2016 IEEE Workshop on Spoken Language Technology, SLT 2016 ; Conference date: 13-12-2016 Through 16-12-2016",  url       = "https://www2.securecms.com/SLT2016//Default.asp", }

@INPROCEEDINGS{Klejch2017,

  author={O. {Klejch} and P. {Bell} and S. {Renals}},

  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 

  title={Sequence-to-sequence models for punctuated transcription combining lexical and acoustic features}, 

  year={2017},

  volume={},

  number={},

  pages={5700-5704},

  doi={10.1109/ICASSP.2017.7953248}}
  
@inproceedings{iwslt2011,
  author    = {M. Federico and
               L. Bentivogli and
               M. Paul and
               S. St{\"{u}}ker},
  title     = {Overview of the {IWSLT} 2011 evaluation campaign},
  booktitle = {2011 International Workshop on Spoken Language Translation, {IWSLT}
               2011, San Francisco, CA, USA, December 8-9, 2011},
  pages     = {11--27},
  publisher = {{ISCA}},
  year      = {2011},
  url       = {http://www.isca-speech.org/archive/iwslt\_11/sltb\_011.html},
  timestamp = {Mon, 31 Mar 2014 16:34:17 +0200},
  biburl    = {https://dblp.org/rec/conf/iwslt/FedericoBPS11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{che2016,
  title={Punctuation prediction for unsegmented transcript based on word vector},
  author={X. Che and C. Wang and H. Yang and C. Meinel},
  booktitle={Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)},
  pages={654--658},
  year={2016}
}

@INPROCEEDINGS{Bell2015,
  author={P. {Bell} and M. J. F. {Gales} and T. {Hain} and J. {Kilgour} and P. {Lanchantin} and X. {Liu} and A. {McParland} and S. {Renals} and O. {Saz} and M. {Wester} and P. C. {Woodland}},
  booktitle={2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)}, 
  title={The MGB challenge: Evaluating multi-genre broadcast media recognition}, 
  year={2015},
  volume={},
  number={},
  pages={687-693},
  doi={10.1109/ASRU.2015.7404863}}
  
  
% only for datasets
@article{batista2011recovering,
  title={Recovering capitalization and punctuation marks on speech transcriptions},
  author={F. Batista and N. Mamede},
  journal={Instituto Superior T{\'e}cnico: PhD Dissertation},
  year={2011},
  publisher={Citeseer}
}

@inproceedings{Ueffing2013,
  title={Improved models for automatic punctuation prediction for spoken and written text},
  author={B. Ueffing and M. Bisani and P. Vozila},
  booktitle={INTERSPEECH},
  year={2013}
}

@article{kim2003,
title = "A combined punctuation generation and speech recognition system and its performance enhancement using prosody",
journal = "Speech Communication",
volume = "41",
number = "4",
pages = "563 - 577",
year = "2003",
issn = "0167-6393",
doi = "https://doi.org/10.1016/S0167-6393(03)00049-9",
url = "http://www.sciencedirect.com/science/article/pii/S0167639303000499",
author = "J. H. Kim and P. C. Woodland",
keywords = "Punctuation generation, Speech recognition, Prosody, Classification And Regression Tree (CART), -best rescoring",
abstract = "A punctuation generation system which combines prosodic information with acoustic and language model information is presented. Experiments have been conducted for both the reference text transcriptions and speech recogniser outputs. For the reference transcription, prosodic information of acoustic data is shown to be more useful than language model information. Several straightforward modifications of a conventional speech recogniser allow the system to produce punctuation and speech recognition hypotheses simultaneously. The multiple hypotheses produced by the automatic speech recogniser are then re-scored using prosodic information. When the prosodic information is incorporated, the F-measure (defined as harmonic mean of recall and precision) can be improved. This speech recognition system including punctuation gives a small reduction in word error rate on the 1-best speech recognition output including punctuation. An alternative approach for generating punctuation from the un-punctuated 1-best speech recognition output is also proposed. The results from these two alternative schemes are compared."
}

@inproceedings{europarl,
author = {C. Juin and R. Wei and L. D'Haro and R. Banchs},
year = {2017},
month = {11},
pages = {1806-1811},
title = {Punctuation prediction using a bidirectional recurrent neural network with part-of-speech tagging},
doi = {10.1109/TENCON.2017.8228151}
}

@misc{zelasko2018,
      title={Punctuation Prediction Model for Conversational Speech}, 
      author={P. Żelasko and P. Szymański and J. Mizgajski and A. Szymczak and Y. Carmiel and N. Dehak},
      year={2018},
      eprint={1807.00543},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@INPROCEEDINGS{gravano2009,  author={A. {Gravano} and M. {Jansche} and M. {Bacchiani}},  booktitle={2009 IEEE International Conference on Acoustics, Speech and Signal Processing},   title={Restoring punctuation and capitalization in transcribed speech},   year={2009},  volume={},  number={},  pages={4741-4744},}

@article{spokenWritten,
author = {B. Zhang},
year = {2013},
month = {07},
pages = {},
title = {An Analysis of Spoken Language and Written Language and How They Affect English Language Learning and Teaching},
volume = {4},
journal = {Journal of Language Teaching and Research},
doi = {10.4304/jltr.4.4.834-838}
}

@inproceedings{Chen1999,
  title={Speech recognition with automatic punctuation},
  author={C. Chen},
  booktitle={EUROSPEECH},
  year={1999}
}

@inproceedings{briscoe2002,
    title = "Robust Accurate Statistical Annotation of General Text",
    author = "T. Briscoe  and
      J. Carroll",
    booktitle = "Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02)",
    month = may,
    year = "2002",
    address = "Las Palmas, Canary Islands - Spain",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2002/pdf/250.pdf",
}

@inproceedings{Huang2002,
  title={Maximum entropy model for punctuation annotation from speech},
  author={J. Huang and G. Zweig},
  booktitle={INTERSPEECH},
  year={2002}
}

@inproceedings{LuNg2010,
author = {W. Lu and H. T. Ng},
title = {Better Punctuation Prediction with Dynamic Conditional Random Fields},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {This paper focuses on the task of inserting punctuation symbols into transcribed conversational speech texts, without relying on prosodic cues. We investigate limitations associated with previous methods, and propose a novel approach based on dynamic conditional random fields. Different from previous work, our proposed approach is designed to jointly perform both sentence boundary and sentence type prediction, and punctuation prediction on speech utterances.We performed evaluations on a transcribed conversational speech domain consisting of both English and Chinese texts. Empirical results show that our method outperforms an approach based on linear-chain conditional random fields and other previous approaches.},
booktitle = {Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing},
pages = {177–186},
numpages = {10},
location = {Cambridge, Massachusetts},
series = {EMNLP '10}
}

@article{wangngsim2012,
author = {X. Wang and H. Ng and K. Sim},
year = {2012},
month = {01},
pages = {},
title = {Dynamic Conditional Random Fields for Joint Sentence Boundary and Punctuation Prediction},
volume = {2},
journal = {13th Annual Conference of the International Speech Communication Association 2012, INTERSPEECH 2012}
}

@inproceedings{Tilk2015,
author = {O. Tilk and T. Alumäe},
year = {2015},
month = {01},
pages = {},
title = {LSTM for Punctuation Restoration in Speech Transcripts}
}

@inproceedings{yitaowen2017,
author = {J. Yi and J. Tao and Z. Wen and Y. Li},
year = {2017},
month = {08},
pages = {2779-2783},
title = {Distilling Knowledge from an Ensemble of Models for Punctuation Prediction},
doi = {10.21437/Interspeech.2017-1079}
}

@misc{sunkara2020,
      title={Multimodal Semi-supervised Learning Framework for Punctuation Prediction in Conversational Speech}, 
      author={M. Sunkara and S. Ronanki and D. Bekal and S. Bodapati and K. Kirchhoff},
      year={2020},
      eprint={2008.00702},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@article{devlin2018,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={J. Devlin and M. W. Chang and K. Lee and K. Toutanova},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@misc{yi2020adversarial,
      title={Adversarial Transfer Learning for Punctuation Restoration}, 
      author={J. Yi and J. Tao and Y. Bai and Z. Tian and C. Fan},
      year={2020},
      eprint={2004.00248},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{crawshaw2020multitask,
      title={Multi-Task Learning with Deep Neural Networks: A Survey}, 
      author={M. Crawshaw},
      year={2020},
      eprint={2009.09796},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{chen2020controllable,
      title={Controllable Time-Delay Transformer for Real-Time Punctuation Prediction and Disfluency Detection}, 
      author={Qian Chen and Mengzhe Chen and Bo Li and Wen Wang},
      year={2020},
      eprint={2003.01309},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{chung2018,
author = {Y. Chung and J. Glass},
year = {2018},
month = {09},
pages = {811-815},
title = {Speech2Vec: A Sequence-to-Sequence Framework for Learning Word Embeddings from Speech},
doi = {10.21437/Interspeech.2018-2341}
}

@misc{huggingface,
author = {T. Wolf and L. Debut and V. Sanh and J. Chaumond and C. Delangue and A. Moi and P. Cistac and T. Rault and R. Louf and M. Funtowicz and J. Brew},
year = {2019},
month = {10},
pages = {},
title = {Transformers: State-of-the-art Natural Language Processing}
}

@misc{transformersurvey,
      title={Pre-trained Models for Natural Language Processing: A Survey}, 
      author={Xipeng Qiu and Tianxiang Sun and Yige Xu and Yunfan Shao and Ning Dai and Xuanjing Huang},
      year={2020},
      eprint={2003.08271},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{roberta,
  author    = {Y. Liu and
               M. Ott and
               N. Goyal and
               J. Du and
               M. Joshi and
               D. Chen and
               O. Levy and
               M. Lewis and
               L. Zettlemoyer and
               V. Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {CoRR},
  volume    = {abs/1907.11692},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.11692},
  archivePrefix = {arXiv},
  eprint    = {1907.11692},
  timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{pennington2014glove,
  author = {J. Pennington and R. Socher and C. D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}

@misc{mikolov2013word2vec,
      title={Efficient Estimation of Word Representations in Vector Space}, 
      author={T. Mikolov and K. Chen and G. Corrado and J. Dean},
      year={2013},
      eprint={1301.3781},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{electra,
      title={ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators}, 
      author={K. Clark and M. T. Luong and Q. V. Le and C. D. Manning},
      year={2020},
      eprint={2003.10555},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{sotapunctuation,
    title = "Punctuation Restoration using Transformer Models for High-and Low-Resource Languages",
    author = "T. Alam  and
      A. Khan and
      F. Alam",
    booktitle = "Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.wnut-1.18",
    doi = "10.18653/v1/2020.wnut-1.18",
    pages = "132--142",
    abstract = "Punctuation restoration is a common post-processing problem for Automatic Speech Recognition (ASR) systems. It is important to improve the readability of the transcribed text for the human reader and facilitate NLP tasks. Current state-of-art address this problem using different deep learning models. Recently, transformer models have proven their success in downstream NLP tasks, and these models have been explored very little for the punctuation restoration problem. In this work, we explore different transformer based models and propose an augmentation strategy for this task, focusing on high-resource (English) and low-resource (Bangla) languages. For English, we obtain comparable state-of-the-art results, while for Bangla, it is the first reported work, which can serve as a strong baseline for future work. We have made our developed Bangla dataset publicly available for the research community.",
}

@misc{tay2020efficient,
      title={Efficient Transformers: A Survey}, 
      author={Y. Tay and M. Dehghani and D. Bahri and D. Metzler},
      year={2020},
      eprint={2009.06732},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{kitaev2020reformer,
      title={Reformer: The Efficient Transformer}, 
      author={Nikita Kitaev and Łukasz Kaiser and Anselm Levskaya},
      year={2020},
      eprint={2001.04451},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wang2020linformer,
      title={Linformer: Self-Attention with Linear Complexity}, 
      author={S. Wang and B. Z. Li and M. Khabsa and H. Fang and H. Ma},
      year={2020},
      eprint={2006.04768},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{li2020train,
      title={Train Large, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers}, 
      author={Z. Li and E. Wallace and S. Shen and K. Lin and K. Keutzer and D. Klein and Joseph E. Gonzalez},
      year={2020},
      eprint={2002.11794},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}



@inproceedings{Lin2020disf,
  author={Binghuai Lin and Liyuan Wang},
  title={{Joint Prediction of Punctuation and Disfluency in Speech Transcripts}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={716--720},
  doi={10.21437/Interspeech.2020-1277},
  url={http://dx.doi.org/10.21437/Interspeech.2020-1277}
}

@misc{han2016compression,
      title={Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding}, 
      author={S. Han and H. Mao and W. J. Dally},
      year={2016},
      eprint={1510.00149},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@InProceedings{interannotator2020,
author="M. Boh{\'a}{\v{c}}
and M. Rott
and V Kov{\'a}{\v{r}}",
editor="Ek{\v{s}}tein, Kamil
and Matou{\v{s}}ek, V{\'a}clav",
title="Text Punctuation: An Inter-annotator Agreement Study",
booktitle="Text, Speech, and Dialogue",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="120--128",
abstract="Spoken language is a phenomenon which is hard to be annotated accurately. One of the most ambiguous tasks is to fill in the punctuation marks into the spoken language transcription. Used punctuation marks are often dependent on how annotators understand the transcription content. This may differ as the spoken language often lacks clear structure (inherent to written language) due to the utterance spontaneity or due to skipping between ideas.",
isbn="978-3-319-64206-2"
}

@misc{vaswani2017,
      title={Attention Is All You Need}, 
      author={A. Vaswani and N. Shazeer and N. Parmar and J. Uszkoreit and L. Jones and A. N. Gomez and L. Kaiser and I. Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{entropy,
author = {C. E. Shannon},
title = {A Mathematical Theory of Communication},
journal = {Bell System Technical Journal},
volume = {27},
number = {3},
pages = {379-423},
doi = {https://doi.org/10.1002/j.1538-7305.1948.tb01338.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/j.1538-7305.1948.tb01338.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/j.1538-7305.1948.tb01338.x},
year = {1948}
}

@article{needleman1970,
title = {A general method applicable to the search for similarities in the amino acid sequence of two proteins},
journal = {Journal of Molecular Biology},
volume = {48},
number = {3},
pages = {443-453},
year = {1970},
issn = {0022-2836},
doi = {https://doi.org/10.1016/0022-2836(70)90057-4},
url = {https://www.sciencedirect.com/science/article/pii/0022283670900574},
author = {S. B. Needleman and C. D. Wunsch},
authors_full = {Needleman-Wunsch},
abstract = {A computer adaptable method for finding similarities in the amino acid sequences of two proteins has been developed. From these findings it is possible to determine whether significant homology exists between the proteins. This information is used to trace their possible evolutionary development. The maximum match is a number dependent upon the similarity of the sequences. One of its definitions is the largest number of amino acids of one protein that can be matched with those of a second protein allowing for all possible interruptions in either of the sequences. While the interruptions give rise to a very large number of comparisons, the method efficiently excludes from consideration those comparisons that cannot contribute to the maximum match. Comparisons are made from the smallest unit of significance, a pair of amino acids, one from each protein. All possible pairs are represented by a two-dimensional array, and all possible comparisons are represented by pathways through the array. For this maximum match only certain of the possible pathways must be evaluated. A numerical value, one in this case, is assigned to every cell in the array representing like amino acids. The maximum match is the largest number that would result from summing the cell values of every pathway.}
}

@article{imbalance,
author = {J. Leevy and T. Khoshgoftaar and R. Bauder and N. Seliya},
year = {2018},
month = {11},
pages = {},
title = {A survey on addressing high-class imbalance in big data},
volume = {5},
journal = {Journal of Big Data},
doi = {10.1186/s40537-018-0151-6}
}

@misc{ma2019nlpaug,
  title={NLP Augmentation},
  author={Edward Ma},
  howpublished={https://github.com/makcedward/nlpaug},
  year={2019}
}


@article{distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.01108}
}

@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{1cycle,
  author    = {L. N. Smith},
  title     = {A disciplined approach to neural network hyper-parameters: Part 1
               - learning rate, batch size, momentum, and weight decay},
  journal   = {CoRR},
  volume    = {abs/1803.09820},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.09820},
  archivePrefix = {arXiv},
  eprint    = {1803.09820},
  timestamp = {Mon, 13 Aug 2018 16:46:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-09820.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{adamw,
  author    = {I. Loshchilov and
               F. Hutter},
  title     = {Fixing Weight Decay Regularization in Adam},
  journal   = {CoRR},
  volume    = {abs/1711.05101},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.05101},
  archivePrefix = {arXiv},
  eprint    = {1711.05101},
  timestamp = {Mon, 13 Aug 2018 16:48:18 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-05101.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}